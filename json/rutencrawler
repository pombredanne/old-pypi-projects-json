{
    "info": {
        "author": "jn8029",
        "author_email": "warren.y.cheng@gmail.com",
        "bugtrack_url": null,
        "classifiers": [
            "License :: OSI Approved :: MIT License",
            "Operating System :: OS Independent",
            "Programming Language :: Python :: 3"
        ],
        "description": "# Ruten Seller Product Parser\n![PyPI version](https://img.shields.io/pypi/pyversions/rutencrawler.svg)\n![PyPI license](https://img.shields.io/pypi/l/rutencrawler.svg)\n![PyPI status](https://img.shields.io/pypi/status/rutencrawler.svg)\n[![Downloads](http://pepy.tech/badge/rutencrawler)](http://pepy.tech/count/rutencrawler)\n\nThis is a repository that offers a ProductCrawler class to crawl Ruten web pages for the product information in json format.\n\n```\nfrom Crawler import ProductCrawler\nseller_ruten_id = \"SELLER_RUTEN_ID\"\nurl =\"https://class.ruten.com.tw/user/index00.php?s={seller_ruten_id}\"\nurl = url.format(seller_ruten_id)\nproduct_crawler = ProductCrawler(url)\nresults = product_crawler.get_crawl_result()\n```\n\n## Overview\n\n```class ProductCrawler``` class handles the whole web crawling logic.  It takes optional arguments of ```sleep_time``` and ```sleep_at_each_iteration```\n\n```class ProductPageParser``` handles the product page information extraction. Currently the parser only extracts shipping information, urls for images and the title of the product. More info can be extracted and the logic can be added here.\n\n```class ProdcutListParser``` handles the parsing of product list page. The main function is to extract a list of product urls at each page, and then the urls are then used to parse product information with ProductPageParser\n\n## To-do\n\n* add more error-proof exception handlers in ProductCrawler due to the multi-threaded nature of the process.\n* add more product info extraction features in ProductCrawler, e.g. price, remaining time, description, etc.\n\n\n\n## Note\n* I did not check/set a limit to the number of threads within the process.\n* Enhancements can be made with thread pool.\n* Wait for 1 seconds per 20 threads\n\n\n# Learning Data Structure & Algorithms on Coursera\nThis is a repository that records what I have learned from the Data Structure & Algorithms Specialization on Coursera taught by UC San Diego\n\nThe [Data Structure & Algorithm Specialization](https://www.coursera.org/specializations/data-structures-algorithms?) on Coursera teaches algorithmic techniques for solving various computational problems with about 100 algorithmic coding problems in any programming language of the student's choice.\n\nThe Specialization includes 6 courses, namely:\n\n* Algorithm Toolbox\n* Data Structure\n* Algorithms on Graphs\n* Algorithms on Strings\n* Advanced Algorithms and Complexity\n* Genome Assembly Programming Challenge\n\n\n\n## Algorithm Toolbox\n#### Big-O Notation\nIn computer science, big O notation is used to classify algorithms according to how their running time or space requirements grow as the input size grows. Click [here](https://tinyurl.com/y9tzg6sh) for the article I wrote to illustrate the basics of this concept.\n#### Greedy Algorithm\nThe basic pattern of a greedy algorithm starts with picking a safe choice to tackle the problem, check that the safe choice works, repeat and solve smaller problems (sub-problem) with safe choices of the same concept and finish when there\u00e2\u20ac\u2122s no smaller problem anymore. Click [here](https://tinyurl.com/y9twoym6) for the article I wrote to illustrate the greedy algorithm with simple toy problems.\n#### Divide & Conquer\n#### Dynamic Programming\n## Data Structures\n#### Stack\nAn abstract data type that allows adding and removing data on a Last-In-First-Out(LIFO) basis. It can be implemented with an array or linked-list.\n#### Queue\n#### Tree\n#### Heap\n#### Priority Queue\n#### Hash Table\n\n\n",
        "description_content_type": "text/markdown",
        "docs_url": null,
        "download_url": "",
        "downloads": {
            "last_day": -1,
            "last_month": -1,
            "last_week": -1
        },
        "home_page": "https://github.com/jn8029/ruten_crawler",
        "keywords": "",
        "license": "",
        "maintainer": "",
        "maintainer_email": "",
        "name": "rutencrawler",
        "package_url": "https://pypi.org/project/rutencrawler/",
        "platform": "",
        "project_url": "https://pypi.org/project/rutencrawler/",
        "project_urls": {
            "Homepage": "https://github.com/jn8029/ruten_crawler"
        },
        "release_url": "https://pypi.org/project/rutencrawler/0.0.3/",
        "requires_dist": [
            "bs4",
            "requests"
        ],
        "requires_python": "",
        "summary": "A crawler for product information of sellers on Ruten.",
        "version": "0.0.3"
    },
    "last_serial": 5011584,
    "releases": {
        "0.0.1": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "6c7425025a38de56736894a9b6010b7e",
                    "sha256": "b9ef99f98c3aca44fee10d0b147fcfc20698393de92ec62e7adfe015738f4edc"
                },
                "downloads": -1,
                "filename": "rutencrawler-0.0.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "6c7425025a38de56736894a9b6010b7e",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 6178,
                "upload_time": "2019-04-01T05:55:35",
                "url": "https://files.pythonhosted.org/packages/a4/af/27e6fc5bd817c7f89644a32c261f75a07d839b02a67821a0cc83608271ca/rutencrawler-0.0.1-py3-none-any.whl"
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "3bf0d6e2f1f5e8294e3a5183e4cfa2a8",
                    "sha256": "931e50913ea4f525b26387be9c1df5e8ee50635c1faae0f4298648f442414411"
                },
                "downloads": -1,
                "filename": "rutencrawler-0.0.1.tar.gz",
                "has_sig": false,
                "md5_digest": "3bf0d6e2f1f5e8294e3a5183e4cfa2a8",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 4443,
                "upload_time": "2019-04-01T05:55:37",
                "url": "https://files.pythonhosted.org/packages/f8/51/3d47db94108f3aab3c921a0edaa3b7448c5c37407a7705027881aeb72d80/rutencrawler-0.0.1.tar.gz"
            }
        ],
        "0.0.2": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "e5e7f940f0d3c11973117402f23d6571",
                    "sha256": "eccda62824ff54346f8beeea69a77acd5ead9a32e9f0a8b9656f0f7b9c109fbe"
                },
                "downloads": -1,
                "filename": "rutencrawler-0.0.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "e5e7f940f0d3c11973117402f23d6571",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 6201,
                "upload_time": "2019-04-01T06:01:25",
                "url": "https://files.pythonhosted.org/packages/4b/60/d964a202890568efbb4e395666b128e98f23017b9ac4d4ec0ef2d6b68b0f/rutencrawler-0.0.2-py3-none-any.whl"
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "a2bc876092df60d7497d43ab5122c36c",
                    "sha256": "ec7c5f40934eeebfd766d284ff7eaee18792b91753dbb8ff6b9ea9ea59e10fe5"
                },
                "downloads": -1,
                "filename": "rutencrawler-0.0.2.tar.gz",
                "has_sig": false,
                "md5_digest": "a2bc876092df60d7497d43ab5122c36c",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 4503,
                "upload_time": "2019-04-01T06:01:27",
                "url": "https://files.pythonhosted.org/packages/84/d2/9e431b6dca58e72315ad227af0afac1fc5a5537ca1415dd594e5ebe34c9d/rutencrawler-0.0.2.tar.gz"
            }
        ],
        "0.0.3": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "b0e683f89040d9ca951486e93d13967b",
                    "sha256": "f1bb8f3e8e6d616b258a71ce838e53277e88b7f20306cee3ad706105498e5c62"
                },
                "downloads": -1,
                "filename": "rutencrawler-0.0.3-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "b0e683f89040d9ca951486e93d13967b",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 6201,
                "upload_time": "2019-04-01T06:02:35",
                "url": "https://files.pythonhosted.org/packages/a3/1c/d55c4e1f9b80e9c7065103b7662adf9fd11814d985ad8e849339d662d716/rutencrawler-0.0.3-py3-none-any.whl"
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "0ac409951873cb75a49b8f082dbaea65",
                    "sha256": "1d4b30560ec4856b174d35fdfb24d56c9f5cb06ba17f4b664bc4830abbbc0d68"
                },
                "downloads": -1,
                "filename": "rutencrawler-0.0.3.tar.gz",
                "has_sig": false,
                "md5_digest": "0ac409951873cb75a49b8f082dbaea65",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 4505,
                "upload_time": "2019-04-01T06:02:37",
                "url": "https://files.pythonhosted.org/packages/a4/de/6ed3134ac81679440f31f6d152e0e10d67bb80a1035608f955eb4dccf461/rutencrawler-0.0.3.tar.gz"
            }
        ]
    },
    "urls": [
        {
            "comment_text": "",
            "digests": {
                "md5": "b0e683f89040d9ca951486e93d13967b",
                "sha256": "f1bb8f3e8e6d616b258a71ce838e53277e88b7f20306cee3ad706105498e5c62"
            },
            "downloads": -1,
            "filename": "rutencrawler-0.0.3-py3-none-any.whl",
            "has_sig": false,
            "md5_digest": "b0e683f89040d9ca951486e93d13967b",
            "packagetype": "bdist_wheel",
            "python_version": "py3",
            "requires_python": null,
            "size": 6201,
            "upload_time": "2019-04-01T06:02:35",
            "url": "https://files.pythonhosted.org/packages/a3/1c/d55c4e1f9b80e9c7065103b7662adf9fd11814d985ad8e849339d662d716/rutencrawler-0.0.3-py3-none-any.whl"
        },
        {
            "comment_text": "",
            "digests": {
                "md5": "0ac409951873cb75a49b8f082dbaea65",
                "sha256": "1d4b30560ec4856b174d35fdfb24d56c9f5cb06ba17f4b664bc4830abbbc0d68"
            },
            "downloads": -1,
            "filename": "rutencrawler-0.0.3.tar.gz",
            "has_sig": false,
            "md5_digest": "0ac409951873cb75a49b8f082dbaea65",
            "packagetype": "sdist",
            "python_version": "source",
            "requires_python": null,
            "size": 4505,
            "upload_time": "2019-04-01T06:02:37",
            "url": "https://files.pythonhosted.org/packages/a4/de/6ed3134ac81679440f31f6d152e0e10d67bb80a1035608f955eb4dccf461/rutencrawler-0.0.3.tar.gz"
        }
    ]
}